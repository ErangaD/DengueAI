{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eminda/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "#copied from benchmark staightforward\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# just for the sake of this blog post!\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the provided data\n",
    "train_features = pd.read_csv('./../original data_set/dengue_features_train.csv',\n",
    "                             index_col=[0,1,2])\n",
    "\n",
    "train_labels = pd.read_csv('./../original data_set/dengue_labels_train.csv',\n",
    "                           index_col=[0,1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate data for San Juan\n",
    "sj_train_features = train_features.loc['sj']\n",
    "sj_train_labels = train_labels.loc['sj']\n",
    "\n",
    "# Separate data for Iquitos\n",
    "iq_train_features = train_features.loc['iq']\n",
    "iq_train_labels = train_labels.loc['iq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('San Juan')\n",
    "print('features: ', sj_train_features.shape)\n",
    "print('labels  : ', sj_train_labels.shape)\n",
    "\n",
    "print('\\nIquitos')\n",
    "print('features: ', iq_train_features.shape)\n",
    "print('labels  : ', iq_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove `week_start_date` string.\n",
    "sj_train_features.drop('week_start_date', axis=1, inplace=True)\n",
    "iq_train_features.drop('week_start_date', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null check\n",
    "pd.isnull(sj_train_features).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((sj_train_features\n",
    "     .station_avg_temp_c *200)\n",
    "     .plot\n",
    "     .line(lw=0.8))\n",
    "\n",
    "((sj_train_labels\n",
    "     .total_cases)\n",
    "     .plot\n",
    "     .line(lw=0.8))\n",
    "\n",
    "\n",
    "plt.title('Variable with total dengue cases')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sj_train_features.fillna(method='ffill', inplace=True)\n",
    "iq_train_features.fillna(method='ffill', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('San Juan')\n",
    "print('mean: ', sj_train_labels.mean()[0])\n",
    "print('var :', sj_train_labels.var()[0])\n",
    "\n",
    "print('\\nIquitos')\n",
    "print('mean: ', iq_train_labels.mean()[0])\n",
    "print('var :', iq_train_labels.var()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sj_train_labels.hist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "iq_train_labels.hist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train_features['total_cases'] = sj_train_labels.total_cases\n",
    "iq_train_features['total_cases'] = iq_train_labels.total_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlations\n",
    "sj_correlations = sj_train_features.corr()\n",
    "iq_correlations = iq_train_features.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot san juan\n",
    "f,ax = plt.subplots(figsize=(18, 18))\n",
    "sns.heatmap(sj_correlations, annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
    "plt.title('San Juan Variable Correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot iquitos\n",
    "f,ax = plt.subplots(figsize=(18, 18))\n",
    "sns.heatmap(iq_correlations, annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
    "plt.title('iquitos Variable Correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# San Juan\n",
    "(sj_correlations\n",
    "     .total_cases\n",
    "     .drop('total_cases') # don't compare with myself\n",
    "     .sort_values(ascending=False)\n",
    "     .plot\n",
    "     .barh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iquitos\n",
    "(iq_correlations\n",
    "     .total_cases\n",
    "     .drop('total_cases') # don't compare with myself\n",
    "     .sort_values(ascending=False)\n",
    "     .plot\n",
    "     .barh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data for san juan\n",
    "def sj_preprocess_data(data_path, labels_path=None):\n",
    "    # load data and set index to city, year, weekofyear\n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "    \n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_avg_temp_c', \n",
    "                 'reanalysis_max_air_temp_k']\n",
    "    df = df[features]\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # add labels to dataframe\n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "    \n",
    "    # separate san juan\n",
    "    sj = df.loc['sj']\n",
    "    \n",
    "    return sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to preprocess iq data\n",
    "def iq_preprocess_data(data_path, labels_path=None):\n",
    "    # load data and set index to city, year, weekofyear\n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "    \n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_min_temp_c', \n",
    "                 'reanalysis_tdtr_k']\n",
    "    df = df[features]\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # add labels to dataframe\n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "    \n",
    "    # separate iquitos\n",
    "    iq = df.loc['iq']\n",
    "    \n",
    "    return iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train = sj_preprocess_data('./../original data_set/dengue_features_train.csv',labels_path=\"/home/viraj/dmProject/data/dengue_labels_train.csv\")\n",
    "iq_train = iq_preprocess_data('/home/viraj/dmProject/data/dengue_features_train.csv',labels_path=\"/home/viraj/dmProject/data/dengue_labels_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train_subtrain = sj_train.head(800)\n",
    "sj_train_subtest = sj_train.tail(sj_train.shape[0] - 800)\n",
    "\n",
    "iq_train_subtrain = iq_train.head(400)\n",
    "iq_train_subtest = iq_train.tail(iq_train.shape[0] - 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def get_best_model_sj(train, test):\n",
    "    # Step 1: specify the form of the model\n",
    "    model_formula = \"total_cases ~ 1 + \" \\\n",
    "                    \"reanalysis_specific_humidity_g_per_kg + \" \\\n",
    "                    \"reanalysis_dew_point_temp_k + \" \\\n",
    "                    \"station_avg_temp_c + \" \\\n",
    "                    \"reanalysis_max_air_temp_k\"\n",
    "    \n",
    "    grid = 10 ** np.arange(-8, -3, dtype=np.float64)\n",
    "                    \n",
    "    best_alpha = []\n",
    "    best_score = 1000\n",
    "        \n",
    "    # Step 2: Find the best hyper parameter, alpha\n",
    "    for alpha in grid:\n",
    "        model = smf.glm(formula=model_formula,\n",
    "                        data=train,\n",
    "                        family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "        results = model.fit()\n",
    "        predictions = results.predict(test).astype(int)\n",
    "        score = eval_measures.meanabs(predictions, test.total_cases)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_alpha = alpha\n",
    "            best_score = score\n",
    "\n",
    "    print('best alpha = ', best_alpha)\n",
    "    print('best score = ', best_score)\n",
    "            \n",
    "    # Step 3: refit on entire dataset\n",
    "    full_dataset = pd.concat([train, test])\n",
    "    model = smf.glm(formula=model_formula,\n",
    "                    data=full_dataset,\n",
    "                    family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_iq(train, test):\n",
    "    # Step 1: specify the form of the model\n",
    "    model_formula = \"total_cases ~ 1 + \" \\\n",
    "                    \"reanalysis_specific_humidity_g_per_kg + \" \\\n",
    "                    \"reanalysis_dew_point_temp_k + \" \\\n",
    "                    \"station_min_temp_c + \" \\\n",
    "                    \"reanalysis_tdtr_k\"\n",
    "    \n",
    "    grid = 10 ** np.arange(-8, -3, dtype=np.float64)\n",
    "                    \n",
    "    best_alpha = []\n",
    "    best_score = 1000\n",
    "        \n",
    "    # Step 2: Find the best hyper parameter, alpha\n",
    "    for alpha in grid:\n",
    "        model = smf.glm(formula=model_formula,\n",
    "                        data=train,\n",
    "                        family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "        results = model.fit()\n",
    "        predictions = results.predict(test).astype(int)\n",
    "        score = eval_measures.meanabs(predictions, test.total_cases)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_alpha = alpha\n",
    "            best_score = score\n",
    "\n",
    "    print('best alpha = ', best_alpha)\n",
    "    print('best score = ', best_score)\n",
    "            \n",
    "    # Step 3: refit on entire dataset\n",
    "    full_dataset = pd.concat([train, test])\n",
    "    model = smf.glm(formula=model_formula,\n",
    "                    data=full_dataset,\n",
    "                    family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_best_model = get_best_model_sj(sj_train_subtrain, sj_train_subtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_best_model = get_best_model_iq(iq_train_subtrain, iq_train_subtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# plot sj\n",
    "sj_train['fitted'] = sj_best_model.fittedvalues\n",
    "sj_train.fitted.plot(ax=axes[0], label=\"Predictions\")\n",
    "sj_train.total_cases.plot(ax=axes[0], label=\"Actual\")\n",
    "\n",
    "# plot iq\n",
    "iq_train['fitted'] = iq_best_model.fittedvalues\n",
    "iq_train.fitted.plot(ax=axes[1], label=\"Predictions\")\n",
    "iq_train.total_cases.plot(ax=axes[1], label=\"Actual\")\n",
    "\n",
    "plt.suptitle(\"Dengue Predicted Cases vs. Actual Cases\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_test = sj_preprocess_data('/home/viraj/dmProject/data/dengue_features_test.csv')\n",
    "iq_test = iq_preprocess_data('/home/viraj/dmProject/data/dengue_features_test.csv')\n",
    "\n",
    "sj_predictions = sj_best_model.predict(sj_test).astype(int)\n",
    "iq_predictions = iq_best_model.predict(iq_test).astype(int)\n",
    "\n",
    "submission = pd.read_csv(\"/home/viraj/dmProject/data/submission_format.csv\",\n",
    "                         index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate([sj_predictions, iq_predictions])\n",
    "submission.to_csv(\"/home/viraj/dmProject/data/submission_seperate_negative_binomial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
